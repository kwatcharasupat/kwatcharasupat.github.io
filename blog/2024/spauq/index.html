<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Quantifying Spatial Audio Quality Impairment | karn watcharasupat </title> <meta name="author" content="karn watcharasupat"> <meta name="description" content="what to do when you have no spatial awareness"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website, music-informatics, machine-learning, signal-processing, deep-learning "> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%90%B1&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://kwatcharasupat.github.io/blog/2024/spauq/"> <script src="/assets/js/theme.js?a5ca4084d3b81624bcfa01156dae2b8e"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">karn</span> watcharasupat </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Quantifying Spatial Audio Quality Impairment</h1> <p class="post-meta"> Created in May 10, 2024 </p> <p class="post-tags"> <a href="/blog/2024"> <i class="fa-solid fa-calendar fa-sm"></i> 2024 </a>   ·   <a href="/blog/tag/spatial-audio"> <i class="fa-solid fa-hashtag fa-sm"></i> spatial-audio</a>   <a href="/blog/tag/dsp"> <i class="fa-solid fa-hashtag fa-sm"></i> dsp</a>     ·   <a href="/blog/category/research"> <i class="fa-solid fa-tag fa-sm"></i> research</a>   </p> </header> <article class="post-content"> <div id="markdown-content"> <p>Spatial audio quality is a highly multifaceted concept (see <a href="https://depositonce.tu-berlin.de/items/50b7777f-ce30-431b-b371-55b977e0f707" rel="external nofollow noopener" target="_blank">this</a> for a very long list of things to consider). “Geometrical” components of spatial audio quality are perhaps the least subjective aspect of spatial audio quality to quantify, yet there have been very little attempt at dealing with it since <a href="https://gitlab.inria.fr/bass-db/bss_eval" rel="external nofollow noopener" target="_blank">BSS Eval</a> came out almost 20(!) years ago.</p> <p>Even the geometrical component of spatial audio quality is not trivial to quantify. We resorted to only considering the interchannel time differences (ITD) and interchannel level differences (ILD) of the test signal relative to a reference signal. With this, it is actually possible to construct a signal model to isolate <em>some</em> of the spatial distortion. By using a combination of Weiner-style least-square optimization and good ol’ correlation maximization, we propose a signal decomposition method to isolate the spatial error, in terms of interchannel gain leakages and changes in relative delays, from a processed signal. These intermediates parameters can then be used as a diagnostic tool to identify the nature of the spatial distortion and to quantify the spatial quality impairment.</p> <p>Our work is open-sourced <a href="https://github.com/kwatcharasupat/spauq" rel="external nofollow noopener" target="_blank">here</a> both as a Python package and a CLI.</p> <div class="repo p-2 text-center"> <a href="https://github.com/kwatcharasupat/spauq" rel="external nofollow noopener" target="_blank"> <img class="repo-img-light w-100" alt="kwatcharasupat/spauq" src="https://github-readme-stats.vercel.app/api/pin/?username=kwatcharasupat&amp;repo=spauq&amp;theme=catppuccin_latte&amp;show_owner=false"> <img class="repo-img-dark w-100" alt="kwatcharasupat/spauq" src="https://github-readme-stats.vercel.app/api/pin/?username=kwatcharasupat&amp;repo=spauq&amp;theme=dark&amp;show_owner=false"> </a> </div> <blockquote> <p>Warning: There’s a lot of math in this section. I’m sorry.</p> </blockquote> <h2 id="methods">Methods</h2> <p>Let’s call the reference signal \(\mathbf{s}[n] \in \mathbb{R}^{C}\) and the test signal \(\hat{\mathbf{s}}[n] \in \mathbb{R}^{C}\). Here, \(C\) is the number of channels and \(n\) is the sample index. The signals might not be of the same length. That’s fine here.</p> <p>We model the \(c\)th channel of the test signal as a sum of all the delayed and scaled channels of the reference signal, plus some other residual noise:</p> \[\hat{s}_c[n] = \underbrace{\sum_{d=1:C} A_{cd} s_d[n - \tau_{cd}]}_{:= \tilde{s}_c[n]} + \mathbf{e}_{\text{resid}}\] <p>We can interpret \(A_{cd}\) as the gain mapping from the \(d\)th channel of the reference signal to the \(c\)th channel of the test signal, and \((\mathbf{T})_{cd} = \tau_{cd}\) as the delay mapping from the \(d\)th channel of the reference signal to the \(c\)th channel of the test signal. Ideally, we want \(A_{cc} = 1\) and \(\tau_{cc} = 0\) for all \(c\), and \(A_{cd} = 0\) for all \(d \neq c\). The term \(\tilde{\mathbf{s}}\) is effectively the spatially distorted version of the clean signal, with no other types of distortion. We cannot actually guarantee that \(e_{\text{resid}}\) will contain no spatially relevant distortions, though. (If anyone has an idea on how to fix this, drop us an email!)</p> <h3 id="objective-function">Objective Function</h3> <p>Now that we have a model for the spatial distortion, we can define an objective function to minimize the residual noise. Basically, we want to find the gain and delay mappings that minimize the difference between the test signal and the spatially distorted reference signal. This is done by minimizing the mean squared error between the test signal and the spatially distorted reference signal:</p> \[\min_{\mathbf{A}, \mathbf{T}} \sum_{\text{valid}\ n} \left\| \hat{\mathbf{s}}[n] - \tilde{\mathbf{s}}[n] \right\|_2^2\] <h3 id="optimization">Optimization</h3> <h4 id="step-1">Step 1</h4> <p>Finding the optimal gain is simple, but finding the optimal delay is not. So in practice, we could not easily do a joint optimization due to the non-convex nature of the objective function with respect to \(\mathbf{T}\). So we resorted to a very simple correlation maximization.</p> \[\tau_{cd} = \underset{-K \le \kappa \le K}{\operatorname{arg\ max}} \left| \underset{f \in \mathfrak{F}}{\mathrm{IDFT}}\left\{ \hat{S}_c[f] \cdot S^\ast_d[f] \cdot |H[f]|^2\right\}[\kappa] \right|\] <p>where \(H\) is an optional low-pass filter if your test signal is too noisy in the high end and \(K\) limits the search space.</p> <h4 id="step-2">Step 2</h4> <p>Once we have the optimal delay, we can find the optimal gain by solving a simple least-square optimization problem. This is very similar to the solution to the Wiener filter. The only differences are that (1) instead of computing an \(N\)-tap filter, we are computing a filter with no regards to the length, as long as there is only one non-zero tap at time \(\tau_{cd}\) with magnitude \(A_{cd}\); and (2) the filter is solved channel by channel.</p> <p>Now, we form the autocorrelation <em>tensor</em> \(\mathbf{R} \in \mathbb{R}^{C \times (C \times C)}\) and the cross-correlation <em>matrix</em> \(\check{\mathbf{R}} \in \mathbb{R}^{C \times C}\).</p> \[(\mathbf{R}^c)_{bd} = \sum_{n} s_b[n - \tau_{cb}]s_d[n-\tau_{cd}]\] \[(\check{\mathbf{R}})_{cd} = \sum_{n} \hat{s}_c[n]s_d[n-\tau_{cd}]\] <h4 id="step-21">Step 2.1</h4> <p>In (very) multichannel audio, sometimes we have silent channels. This makes parameter estimation very unstable. Like all problems in life, we pretend it’s not there and proceed.</p> \[\mathfrak{C}^{\perp} := \left\{c \in 1:C \mid \textstyle\sum_n |s_c[n]|^2 &lt; \epsilon\right\}\] \[\mathfrak{D}^{\perp} := \left\{d \in 1:C \mid \textstyle\sum_n |\hat{s}_d[n]|^2 &lt; \epsilon\right\}\] \[\mathbf{A}_{\mathfrak{C}^{\perp}, :} \gets \mathbf{0},\quad \mathbf{A}_{:, \mathfrak{D}^{\perp}} \gets \mathbf{0}\] <h4 id="step-3">Step 3</h4> <p>Now, we can do the highly anticipated matrix inversion.</p> \[\mathbf{A}_{c,\mathfrak{D}} = \check{\mathbf{R}}_{c, \mathfrak{D}}\left(\mathbf{R}^{c}_{\mathfrak{D},\mathfrak{D}}\right)^{-1}\] <blockquote> <p>It’s a lot less math from here.</p> </blockquote> <h3 id="error-decomposition">Error Decomposition</h3> <p>Let’s recap a little. We have</p> \[\hat{\mathbf{s}} = \tilde{\mathbf{s}} + \mathbf{e}_{\text{resid}}\] <p>but \(\tilde{\mathbf{s}}\) itself can be written as \(\tilde{\mathbf{s}} = \mathbf{s} + \mathbf{e}_{\text{spat}}\) where \(\mathbf{e}_{\text{spat}}\) is the noise that we know is definitely spatially related. Additive decomposition is not always the best way to do this, but it’s the easiest to understand. Let’s stick with this for now.</p> <p>Now, we have two types of errors: the residual error and the spatial error. This now allow us to do what the <em>source image to spatial distortion ratio (ISR)</em> from BSS Eval originally set out to do. With this, we have the SNR-style metrics for spatial distortion, <strong>Signal to Spatial Distortion Ratio (SSR)</strong>:</p> \[\text{SSR}(\hat{\mathbf{s}}; \mathbf{s}) = 10 \log_{10} \dfrac{\|\mathbf{s}\|^2}{\|\mathbf{e}_\text{spat}\|^2}\] <p>This measures the “amount” of spatial distortion in the signal, regardless of how much other types of distortion there are in the test signal.</p> <p>The SSR also comes with a cousin, the <strong>Signal to Residual Distortion Ratio (SRR)</strong>:</p> \[\text{SRR}(\hat{\mathbf{s}}; \mathbf{s}) = 10 \log_{10} \dfrac{\|\tilde{\mathbf{s}}\|^2}{\|\mathbf{e}_\text{resid}\|^2}\] <p>This measures the “amount” of residual distortion in the signal, regardless of how much spatial distortion there are in the test signal.</p> <h2 id="some-benchmarks">Some Benchmarks</h2> <p>Although this work is designed to be a purely objective (instead of perceptual) tool, in that the main contribution is in the estimation of \(\mathbf{A}\) and \(\mathbf{T}\), we still need to verify that the SSR and SRR has the properties of (1) being robust to non-spatial distortion and (2) follows some perceptual intuition for well-established understanding of spatial audio quality.</p> <h3 id="robustness-benchmark">Robustness Benchmark</h3> <p>For this we stereoify the well-known Speech dataset <a href="https://catalog.ldc.upenn.edu/LDC93S1" rel="external nofollow noopener" target="_blank">TIMIT</a> and test the metrics against panning, delay, filtering, and noise.</p> <p><em>Panning only</em></p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/pdf/2024-05-10-spauq/pan-480.webp 480w,/assets/pdf/2024-05-10-spauq/pan-800.webp 800w,/assets/pdf/2024-05-10-spauq/pan-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/pdf/2024-05-10-spauq/pan.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p><em>Panning and delay</em></p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/pdf/2024-05-10-spauq/delaypan-480.webp 480w,/assets/pdf/2024-05-10-spauq/delaypan-800.webp 800w,/assets/pdf/2024-05-10-spauq/delaypan-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/pdf/2024-05-10-spauq/delaypan.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p><em>Panning and low-pass filter</em></p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/pdf/2024-05-10-spauq/lpfpan-480.webp 480w,/assets/pdf/2024-05-10-spauq/lpfpan-800.webp 800w,/assets/pdf/2024-05-10-spauq/lpfpan-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/pdf/2024-05-10-spauq/lpfpan.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p><em>Panning and noise</em></p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/pdf/2024-05-10-spauq/snrpan-480.webp 480w,/assets/pdf/2024-05-10-spauq/snrpan-800.webp 800w,/assets/pdf/2024-05-10-spauq/snrpan-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/pdf/2024-05-10-spauq/snrpan.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>We also test the system by using the <a href="https://leomccormack.github.io/sparta-site/" rel="external nofollow noopener" target="_blank">SPARTA</a> to spatialize TIMIT and <a href="https://zenodo.org/records/6387880" rel="external nofollow noopener" target="_blank">STARSS22</a> to 5 channels. For those with theoretical values, you will also see dotted lines in the figure below.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/pdf/2024-05-10-spauq/starss-480.webp 480w,/assets/pdf/2024-05-10-spauq/starss-800.webp 800w,/assets/pdf/2024-05-10-spauq/starss-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/pdf/2024-05-10-spauq/starss.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h3 id="codec-benchmark">Codec Benchmark</h3> <p>For this we use <a href="https://zenodo.org/records/3338373" rel="external nofollow noopener" target="_blank">MUSDB18-HQ</a> and compressed it using AAC under different stereo coding settings and test the compressed signals against the original.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/pdf/2024-05-10-spauq/aac-musdb-480.webp 480w,/assets/pdf/2024-05-10-spauq/aac-musdb-800.webp 800w,/assets/pdf/2024-05-10-spauq/aac-musdb-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/pdf/2024-05-10-spauq/aac-musdb.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>This figure is the same results as the above but we replotted-it to show the relative distortion instead of the absolute distortion. This clearly shows the tradeoff between using L/R, M/S, and joint coding as the bits are allocated between the content and the spatialization.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/pdf/2024-05-10-spauq/aac-musdb-rel-480.webp 480w,/assets/pdf/2024-05-10-spauq/aac-musdb-rel-800.webp 800w,/assets/pdf/2024-05-10-spauq/aac-musdb-rel-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/pdf/2024-05-10-spauq/aac-musdb-rel.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h2 id="conclusion">Conclusion</h2> <p>In this work, we propose a decomposition technique (that’s actually quite simple) to isolate the spatial distortion parameters, namely, the gain mapping and delay mapping matrices. Using these parameters, a number of downstream metrics can be proposed. We demonstrate two very simple energy-ratio metrics and benchmarked it against a number of spatial distortion scenarios.</p> </div> </article> <br> <hr> <br> If you found this useful, please cite this as: <blockquote> <p>watcharasupat, karn (May 2024). Quantifying Spatial Audio Quality Impairment. https://kwatcharasupat.github.io.</p> </blockquote> <p>or as a BibTeX entry:</p> <div class="language-bibtex highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nc">@article</span><span class="p">{</span><span class="nl">watcharasupat2024quantifying-spatial-audio-quality-impairment</span><span class="p">,</span>
  <span class="na">title</span>   <span class="p">=</span> <span class="s">{Quantifying Spatial Audio Quality Impairment}</span><span class="p">,</span>
  <span class="na">author</span>  <span class="p">=</span> <span class="s">{watcharasupat, karn}</span><span class="p">,</span>
  <span class="na">year</span>    <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">month</span>   <span class="p">=</span> <span class="s">{May}</span><span class="p">,</span>
  <span class="na">url</span>     <span class="p">=</span> <span class="s">{https://kwatcharasupat.github.io/blog/2024/spauq/}</span>
<span class="p">}</span>
</code></pre></div></div> <div id="giscus_thread" style="max-width: 800px; margin: 0 auto;"> <script>let giscusTheme=determineComputedTheme(),giscusAttributes={src:"https://giscus.app/client.js","data-repo":"kwatcharasupat/kwatcharasupat.github.io","data-repo-id":"R_kgDOL5j_Ew","data-category":"Comments","data-category-id":"DIC_kwDOL5j_E84CfQr5","data-mapping":"title","data-strict":"1","data-reactions-enabled":"1","data-emit-metadata":"0","data-input-position":"bottom","data-theme":giscusTheme,"data-lang":"en",crossorigin:"anonymous",async:""},giscusScript=document.createElement("script");Object.entries(giscusAttributes).forEach(([t,a])=>giscusScript.setAttribute(t,a)),document.getElementById("giscus_thread").appendChild(giscusScript);</script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 karn watcharasupat. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?b7816bd189846d29eded8745f9c4cf77"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-0CJ2WMKNQY"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-0CJ2WMKNQY");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>